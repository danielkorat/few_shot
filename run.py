from utils import *

def main():
    # ds_dict = load_all_datasets(train_size=200)
    # run_ds_examples(ds=ds_dict['rest']['train'], model='roberta-base', pattern=P5, top_k=10)

    # for domain in 'rest', 'lap':
    #     mlm_splits(ds_dict, domain, P5)

    # # Evaluate with a Pre-Trained Language Model
    # for domain in 'rest', 'lap':
    #     metrics = eval_ds(ds_dict, domain, model='roberta-base', pattern=P5, top_k=10)
    #     print(f"Evaluation results on '{domain}' train data:\n{metrics}\n")
        
    #     # reads output files generated by eval_ds()
    #     post_metrics = post_eval(ds_dict, domain, model='roberta-base', pattern=P5, top_k=10)
    #     print(f"Post-Evaluation results on '{domain}' train data:\n{post_metrics}\n")
    

    # Pattern MLM training

    # Run this training command in shell:
    # python run_pattern_mlm.py --seed=42 --num_train_epochs=1 --learning_rate=5e-04 --line_by_line \
    #     --output_dir=mlm_output --train_file=data/lap_train.txt --validation_file=data/rest_test.txt --per_device_train_batch_size=1 \
    #     --model_type=roberta --model_name_or_path=roberta-base --do_train --do_eval \
    #     --overwrite_output_dir --overwrite_cache --evaluation_strategy=epoch


    # PET hparams: 
    # lr=1x10^-5, batch_size=16, max_len=256, steps=1000
    # every batch: 4 labelled + 12 unlabelled

    new_model_name = 'mlm_output'
    # Evaluate with the newly trained language model
    for domain in 'rest', 'lap':
        metrics = eval_ds(ds_dict, domain, model=new_model_name, pattern=P5, top_k=10)
        print(f"Evaluation results on '{domain}' train data:\n{metrics}\n")
        
        # reads output files generated by eval_ds()
        post_metrics = post_eval(ds_dict, domain, model=new_model_name, pattern=P5, top_k=10)
        print(f"Post-Evaluation results on '{domain}' train data:\n{post_metrics}\n")

if __name__ == "__main__":
    main()
