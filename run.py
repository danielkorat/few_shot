from utils import *

def main():
    ds_dict = load_all_datasets(train_size=200)
    # run_ds_examples(ds=ds_dict['res']['train'], model='roberta-base', pattern=P5, top_k=10)

    # Evaluate with a Pre-Trained Language Model
    for domain in 'res', 'lap':
        metrics = eval_ds(ds_dict, domain, model='roberta-base', pattern=P5, top_k=10)
        print(f"Evaluation results on '{domain}' train data:\n{metrics}\n")
        
        # reads output files generated by eval_ds()
        post_metrics = post_eval(ds_dict, domain, model='roberta-base', pattern=P5, top_k=10)
        print(f"Post-Evaluation results on '{domain}' train data:\n{post_metrics}\n")
    

    # Pattern MLM training

    # Run this training command in shell:

    # run_pattern_mlm.py --seed=42 --num_train_epochs=2 --learning_rate=5e-04 --line_by_line \
    #     --output_dir=. --train_file=train.txt --validation_file=test.txt --per_device_train_batch_size=1 \
    #     --model_type=roberta --model_name_or_path=roberta-base --do_train --do_eval \
    #     --overwrite_output_dir --overwrite_cache --evaluation_strategy=epoch


    # PET hparams: 
    # lr=1x10^-5, batch_size=16, max_len=256, steps=1000
    # every batch: 4 labelled + 12 unlabelled

    new_model_name = 'checkpoint-1000'
    # Evaluate with the newly trained language model
    for domain in 'res', 'lap':
        metrics = eval_ds(ds_dict, domain, model=new_model_name, pattern=P5, top_k=10)
        print(f"Evaluation results on '{domain}' train data:\n{metrics}\n")
        
        # reads output files generated by eval_ds()
        post_metrics = post_eval(ds_dict, domain, model=new_model_name, pattern=P5, top_k=10)
        print(f"Post-Evaluation results on '{domain}' train data:\n{post_metrics}\n")

if __name__ == "__main__":
    main()
